{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNfP4dV7KvdBFuqdoM3mmoX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sohvun/2024AID/blob/huisoo/step1/plate_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 차량 번호판 인식\n"
      ],
      "metadata": {
        "id": "fb8M1GEdVthp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. 설치"
      ],
      "metadata": {
        "id": "cEriNP_NdXeg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 구글 드라이브 마운트"
      ],
      "metadata": {
        "id": "pyd7IxObWOfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJ0Nvu9f1pTw",
        "outputId": "6736bdc2-5de9-4885-db4e-c3c767299eec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### opencv 설치"
      ],
      "metadata": {
        "id": "ER5uWEu5WQrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Dn2buJED-WpR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e6dbf53-4912-4348-f436-65981947a01f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.9.0.80)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### yolo 설치"
      ],
      "metadata": {
        "id": "vU4U3GtgWTtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights\n",
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FSFpfY5V8UwX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcc72984-a310-47cc-9e05-afb9b2793e86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-01 19:43:06--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 162.0.215.52\n",
            "Connecting to pjreddie.com (pjreddie.com)|162.0.215.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights’\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M  35.8MB/s    in 6.6s    \n",
            "\n",
            "2024-06-01 19:43:13 (36.0 MB/s) - ‘yolov3.weights’ saved [248007048/248007048]\n",
            "\n",
            "--2024-06-01 19:43:13--  https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8342 (8.1K) [text/plain]\n",
            "Saving to: ‘yolov3.cfg’\n",
            "\n",
            "yolov3.cfg          100%[===================>]   8.15K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-06-01 19:43:13 (69.3 MB/s) - ‘yolov3.cfg’ saved [8342/8342]\n",
            "\n",
            "--2024-06-01 19:43:14--  https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 625 [text/plain]\n",
            "Saving to: ‘coco.names’\n",
            "\n",
            "coco.names          100%[===================>]     625  --.-KB/s    in 0s      \n",
            "\n",
            "2024-06-01 19:43:14 (38.0 MB/s) - ‘coco.names’ saved [625/625]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### easyocr 설치"
      ],
      "metadata": {
        "id": "gw-PMnOjWhxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easyocr"
      ],
      "metadata": {
        "id": "wM5HVK8_hsxP",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f8e93aa-9c34-4883-9da5-b17abd1eca78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting easyocr\n",
            "  Downloading easyocr-1.7.1-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.18.0+cu121)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.9.0.80)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.11.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr) (9.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.19.3)\n",
            "Collecting python-bidi (from easyocr)\n",
            "  Downloading python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.4)\n",
            "Collecting pyclipper (from easyocr)\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from easyocr)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->easyocr)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->easyocr)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->easyocr)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->easyocr)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->easyocr)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->easyocr)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->easyocr)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->easyocr)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->easyocr)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->easyocr)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->easyocr)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->easyocr)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from python-bidi->easyocr) (1.16.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2024.5.22)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (24.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easyocr) (1.3.0)\n",
            "Installing collected packages: pyclipper, ninja, python-bidi, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, easyocr\n",
            "Successfully installed easyocr-1.7.1 ninja-1.11.1.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pyclipper-1.3.0.post5 python-bidi-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### pytorch(cuda) 설치"
      ],
      "metadata": {
        "id": "NbI-8ipVWnZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117"
      ],
      "metadata": {
        "id": "zVjtIjbxWfJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ee6f488-9efe-4b5e-fd91-947b6556d41c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu117\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 라이브러리 임포트"
      ],
      "metadata": {
        "id": "M46PiPU6WsR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import easyocr\n",
        "import re"
      ],
      "metadata": {
        "id": "z2xkD4SnH4Am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Is CUDA available?"
      ],
      "metadata": {
        "id": "wRdojlNgXBVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"CUDA available:\", torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "FrSwUBgWUcgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 차량 추출"
      ],
      "metadata": {
        "id": "TBHo3V6rdUn_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 객체 탐지 준비"
      ],
      "metadata": {
        "id": "Ti0BgyQlXHZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 클래스 이름 로드\n",
        "with open('coco.names', 'r') as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "# 네트워크 로드\n",
        "net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg')"
      ],
      "metadata": {
        "id": "T67vHY5B8p--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 객체 탐지"
      ],
      "metadata": {
        "id": "ScWrR21hXKMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image(image):\n",
        "    height, width = image.shape[:2]\n",
        "\n",
        "    # 블롭 생성\n",
        "    blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "    net.setInput(blob)\n",
        "\n",
        "    # 레이어 이름 가져오기\n",
        "    layer_names = net.getLayerNames()\n",
        "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "    # 추론 실행\n",
        "    outs = net.forward(output_layers)\n",
        "\n",
        "    return outs, height, width"
      ],
      "metadata": {
        "id": "jccMIWOp9K9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 객체 정보 추출"
      ],
      "metadata": {
        "id": "zgdpuuShXXMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_object(outs, width, height):\n",
        "    # 박스 정보 초기화\n",
        "    class_ids = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "\n",
        "    # 탐지 결과 분석\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5:\n",
        "                # 객체 탐지\n",
        "                center_x = int(detection[0] * width)\n",
        "                center_y = int(detection[1] * height)\n",
        "                w = int(detection[2] * width)\n",
        "                h = int(detection[3] * height)\n",
        "                x = int(center_x - w / 2)\n",
        "                y = int(center_y - h / 2)\n",
        "                boxes.append([x, y, w, h])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "    # 노이즈 제거\n",
        "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "\n",
        "    return boxes, confidences, class_ids, indexes"
      ],
      "metadata": {
        "id": "HS8dE-l69ppR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 차량 식별"
      ],
      "metadata": {
        "id": "MfTabbeVX1jJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_car(boxes, confidences, class_ids, indexes):\n",
        "    # 탐지된 차량 영역 잘라내기 및 신뢰도 점수 저장\n",
        "    detected_car_images = []\n",
        "    car_confidences = []\n",
        "    for i in range(len(boxes)):\n",
        "        if i in indexes:\n",
        "            x, y, w, h = boxes[i]\n",
        "            label = str(classes[class_ids[i]])\n",
        "            confidence = confidences[i]\n",
        "            if label == 'car':  # 차만 탐지\n",
        "                cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "                cv2.putText(image, f'{label} {confidence:.2f}', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "                # 차량 영역 잘라내기\n",
        "                car_img = image[y:y+h, x:x+w]\n",
        "                detected_car_images.append(car_img)\n",
        "                car_confidences.append(confidence)\n",
        "\n",
        "    return detected_car_images, car_confidences"
      ],
      "metadata": {
        "id": "hDn3BsDY-MwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 차량 선택"
      ],
      "metadata": {
        "id": "_80PINUiYE4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def select_car(detected_car_images, car_confidences):\n",
        "    # 신뢰도 점수가 가장 높은 차량 선택\n",
        "    max_confidence_idx = np.argmax(car_confidences)\n",
        "    best_car_img = detected_car_images[max_confidence_idx]\n",
        "\n",
        "    # # 가장 높은 신뢰도 점수를 가진 차량 이미지 출력\n",
        "    # plt.figure(figsize=(10, 10))\n",
        "    # plt.imshow(cv2.cvtColor(best_car_img, cv2.COLOR_BGR2RGB))\n",
        "    # plt.title(image_file)\n",
        "    # plt.axis('off')\n",
        "    # plt.show()\n",
        "\n",
        "    return best_car_img"
      ],
      "metadata": {
        "id": "Ji-hP9ww-iVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 번호판 추출"
      ],
      "metadata": {
        "id": "xCo5eb4qh_Oa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 이미지 정보 추출"
      ],
      "metadata": {
        "id": "fBofSJRxYPIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image(best_car_img):\n",
        "  height, width, channel = best_car_img.shape\n",
        "\n",
        "  # plt.figure(figsize=(12, 10))\n",
        "  # plt.imshow(best_car_img, cmap='gray')\n",
        "  # plt.show()\n",
        "\n",
        "  return height, width, channel"
      ],
      "metadata": {
        "id": "Zv6I1Z25-5fK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 그레이스케일 변환"
      ],
      "metadata": {
        "id": "GwuYYHCyYUjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_gray(best_car_img):\n",
        "    gray = cv2.cvtColor(best_car_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # plt.figure(figsize=(12, 10))\n",
        "    # plt.imshow(gray, cmap='gray')\n",
        "    # plt.show()\n",
        "\n",
        "    return gray"
      ],
      "metadata": {
        "id": "RsklRfA9_KeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 가우시안 블러 적용"
      ],
      "metadata": {
        "id": "OJ5B0AzGYcsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def blur_image(gray):\n",
        "  img_blurred = cv2.GaussianBlur(gray, ksize=(5, 5), sigmaX=0)\n",
        "\n",
        "  # plt.figure(figsize=(12,10))\n",
        "  # plt.imshow(img_blurred, cmap='gray')\n",
        "  # plt.show()\n",
        "\n",
        "  return img_blurred"
      ],
      "metadata": {
        "id": "I7AHNmam_Qqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 이미지 이진화"
      ],
      "metadata": {
        "id": "o1q3GwhSYkx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def threshold_image(img_blurred):\n",
        "  img_thresh = cv2.adaptiveThreshold(\n",
        "      img_blurred,\n",
        "      maxValue=255.0,\n",
        "      adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "      thresholdType=cv2.THRESH_BINARY_INV,\n",
        "      blockSize=19,\n",
        "      C=9\n",
        "  )\n",
        "\n",
        "  # plt.figure(figsize=(12, 10))\n",
        "  # plt.imshow(img_thresh, cmap='gray')\n",
        "  # plt.show()\n",
        "\n",
        "  return img_thresh"
      ],
      "metadata": {
        "id": "36rWVvlz_b_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 외곽선(객체 경계) 찾기"
      ],
      "metadata": {
        "id": "BB2i2tINYuKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_contours(img_thresh, height, width, channel):\n",
        "  contours, _ = cv2.findContours(\n",
        "      img_thresh,\n",
        "      mode=cv2.RETR_LIST,\n",
        "      method=cv2.CHAIN_APPROX_SIMPLE\n",
        "  )\n",
        "\n",
        "  temp_result = np.zeros((height, width, channel), dtype=np.uint8)\n",
        "\n",
        "  cv2.drawContours(temp_result, contours, -1, color=(255, 255, 255))\n",
        "\n",
        "  # plt.figure(figsize=(12, 10))\n",
        "  # plt.imshow(temp_result)\n",
        "  # plt.show()\n",
        "\n",
        "  return contours, temp_result"
      ],
      "metadata": {
        "id": "sbH4MCi0_rDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 외곽선 정보 추출"
      ],
      "metadata": {
        "id": "RXqrufOJY5U-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_contours(contours, temp_result):\n",
        "  contours_dict = []\n",
        "\n",
        "  for contour in contours:\n",
        "      x, y, w, h = cv2.boundingRect(contour)\n",
        "      cv2.rectangle(temp_result, pt1=(x, y), pt2=(x+w, y+h), color=(255, 255, 255), thickness=2)\n",
        "\n",
        "      contours_dict.append({\n",
        "          'contour': contour,\n",
        "          'x': x,\n",
        "          'y': y,\n",
        "          'w': w,\n",
        "          'h': h,\n",
        "          'cx': x + (w / 2),\n",
        "          'cy': y + (h / 2)\n",
        "      })\n",
        "\n",
        "  # plt.figure(figsize=(12, 10))\n",
        "  # plt.imshow(temp_result, cmap='gray')\n",
        "  # plt.show()\n",
        "\n",
        "  return contours_dict"
      ],
      "metadata": {
        "id": "ompLdrzZ_mKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 외곽선 필터링"
      ],
      "metadata": {
        "id": "y1CabTt9ZD9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MIN_AREA = 80\n",
        "MIN_WIDTH, MIN_HEIGHT = 2, 8\n",
        "MIN_RATIO, MAX_RATIO = 0.25, 1.0\n",
        "\n",
        "def draw_bounding_boxes(contours_dict, height, width, channel):\n",
        "  possible_contours = []\n",
        "\n",
        "  cnt = 0\n",
        "  for d in contours_dict:\n",
        "      area = d['w'] * d['h']\n",
        "      ratio = d['w'] / d['h']\n",
        "\n",
        "      if area > MIN_AREA \\\n",
        "      and d['w'] > MIN_WIDTH and d['h'] > MIN_HEIGHT \\\n",
        "      and MIN_RATIO < ratio < MAX_RATIO:\n",
        "          d['idx'] = cnt\n",
        "          cnt += 1\n",
        "          possible_contours.append(d)\n",
        "\n",
        "  # visualize possible contours\n",
        "  temp_result = np.zeros((height, width, channel), dtype=np.uint8)\n",
        "\n",
        "  for d in possible_contours:\n",
        "      # cv2.drawContours(temp_result, d['contour'], -1, (255, 255, 255))\n",
        "      cv2.rectangle(temp_result, pt1=(d['x'], d['y']), pt2=(d['x']+d['w'], d['y']+d['h']), color=(255, 255, 255), thickness=2)\n",
        "\n",
        "  # plt.figure(figsize=(12, 10))\n",
        "  # plt.imshow(temp_result, cmap='gray')\n",
        "  # plt.show()\n",
        "\n",
        "  return possible_contours"
      ],
      "metadata": {
        "id": "OXnxjj_wALOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 외곽선 매칭"
      ],
      "metadata": {
        "id": "kuPvBJDlZHQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_DIAG_MULTIPLYER = 5 # 5\n",
        "MAX_ANGLE_DIFF = 12.0 # 12.0\n",
        "MAX_AREA_DIFF = 0.5 # 0.5\n",
        "MAX_WIDTH_DIFF = 0.8\n",
        "MAX_HEIGHT_DIFF = 0.2\n",
        "MIN_N_MATCHED = 5 # 3\n",
        "\n",
        "def find_matching_contours(possible_contours, height, width, channel):\n",
        "  def find_chars(contour_list):\n",
        "      matched_result_idx = []\n",
        "\n",
        "      for d1 in contour_list:\n",
        "          matched_contours_idx = []\n",
        "          for d2 in contour_list:\n",
        "              if d1['idx'] == d2['idx']:\n",
        "                  continue\n",
        "\n",
        "              dx = abs(d1['cx'] - d2['cx'])\n",
        "              dy = abs(d1['cy'] - d2['cy'])\n",
        "\n",
        "              diagonal_length1 = np.sqrt(d1['w'] ** 2 + d1['h'] ** 2)\n",
        "\n",
        "              distance = np.linalg.norm(np.array([d1['cx'], d1['cy']]) - np.array([d2['cx'], d2['cy']]))\n",
        "              if dx == 0:\n",
        "                  angle_diff = 90\n",
        "              else:\n",
        "                  angle_diff = np.degrees(np.arctan(dy / dx))\n",
        "              area_diff = abs(d1['w'] * d1['h'] - d2['w'] * d2['h']) / (d1['w'] * d1['h'])\n",
        "              width_diff = abs(d1['w'] - d2['w']) / d1['w']\n",
        "              height_diff = abs(d1['h'] - d2['h']) / d1['h']\n",
        "\n",
        "              if distance < diagonal_length1 * MAX_DIAG_MULTIPLYER \\\n",
        "              and angle_diff < MAX_ANGLE_DIFF and area_diff < MAX_AREA_DIFF \\\n",
        "              and width_diff < MAX_WIDTH_DIFF and height_diff < MAX_HEIGHT_DIFF:\n",
        "                  matched_contours_idx.append(d2['idx'])\n",
        "\n",
        "          # append this contour\n",
        "          matched_contours_idx.append(d1['idx'])\n",
        "\n",
        "          if len(matched_contours_idx) < MIN_N_MATCHED:\n",
        "              continue\n",
        "\n",
        "          matched_result_idx.append(matched_contours_idx)\n",
        "\n",
        "          unmatched_contour_idx = []\n",
        "          for d4 in contour_list:\n",
        "              if d4['idx'] not in matched_contours_idx:\n",
        "                  unmatched_contour_idx.append(d4['idx'])\n",
        "\n",
        "          unmatched_contour = np.take(possible_contours, unmatched_contour_idx)\n",
        "\n",
        "          # recursive\n",
        "          recursive_contour_list = find_chars(unmatched_contour)\n",
        "\n",
        "          for idx in recursive_contour_list:\n",
        "              matched_result_idx.append(idx)\n",
        "\n",
        "          break\n",
        "\n",
        "      return matched_result_idx\n",
        "\n",
        "  result_idx = find_chars(possible_contours)\n",
        "\n",
        "  matched_result = []\n",
        "  for idx_list in result_idx:\n",
        "      matched_result.append(np.take(possible_contours, idx_list))\n",
        "\n",
        "  # visualize possible contours\n",
        "  temp_result = np.zeros((height, width, channel), dtype=np.uint8)\n",
        "\n",
        "  for r in matched_result:\n",
        "      for d in r:\n",
        "  #         cv2.drawContours(temp_result, d['contour'], -1, (255, 255, 255))\n",
        "          cv2.rectangle(temp_result, pt1=(d['x'], d['y']), pt2=(d['x']+d['w'], d['y']+d['h']), color=(255, 255, 255), thickness=2)\n",
        "\n",
        "  # plt.figure(figsize=(12, 10))\n",
        "  # plt.imshow(temp_result, cmap='gray')\n",
        "  # plt.show()\n",
        "\n",
        "  return matched_result"
      ],
      "metadata": {
        "id": "S3QzHMvLAfrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 번호판 선택"
      ],
      "metadata": {
        "id": "vDpTprSxZRxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PLATE_WIDTH_PADDING = 1.3 # 1.3\n",
        "PLATE_HEIGHT_PADDING = 1.5 # 1.5\n",
        "MIN_PLATE_RATIO = 3\n",
        "MAX_PLATE_RATIO = 10\n",
        "\n",
        "def extract_plate_images(filtered_matched_result, img_thresh, width, height):\n",
        "  plate_imgs = []\n",
        "  plate_infos = []\n",
        "\n",
        "  for i, matched_chars in enumerate(filtered_matched_result):\n",
        "      sorted_chars = sorted(matched_chars, key=lambda x: x['cx'])\n",
        "\n",
        "      plate_cx = (sorted_chars[0]['cx'] + sorted_chars[-1]['cx']) / 2\n",
        "      plate_cy = (sorted_chars[0]['cy'] + sorted_chars[-1]['cy']) / 2\n",
        "\n",
        "      plate_width = (sorted_chars[-1]['x'] + sorted_chars[-1]['w'] - sorted_chars[0]['x']) * PLATE_WIDTH_PADDING\n",
        "\n",
        "      sum_height = 0\n",
        "      for d in sorted_chars:\n",
        "          sum_height += d['h']\n",
        "\n",
        "      plate_height = int(sum_height / len(sorted_chars) * PLATE_HEIGHT_PADDING)\n",
        "\n",
        "      triangle_height = sorted_chars[-1]['cy'] - sorted_chars[0]['cy']\n",
        "      triangle_hypotenus = np.linalg.norm(\n",
        "          np.array([sorted_chars[0]['cx'], sorted_chars[0]['cy']]) -\n",
        "          np.array([sorted_chars[-1]['cx'], sorted_chars[-1]['cy']])\n",
        "      )\n",
        "\n",
        "      angle = np.degrees(np.arcsin(triangle_height / triangle_hypotenus))\n",
        "\n",
        "      rotation_matrix = cv2.getRotationMatrix2D(center=(plate_cx, plate_cy), angle=angle, scale=1.0)\n",
        "\n",
        "      img_rotated = cv2.warpAffine(img_thresh, M=rotation_matrix, dsize=(width, height))\n",
        "\n",
        "      img_cropped = cv2.getRectSubPix(\n",
        "          img_rotated,\n",
        "          patchSize=(int(plate_width), int(plate_height)),\n",
        "          center=(int(plate_cx), int(plate_cy))\n",
        "      )\n",
        "\n",
        "      if img_cropped.shape[1] / img_cropped.shape[0] < MIN_PLATE_RATIO or img_cropped.shape[1] / img_cropped.shape[0] < MIN_PLATE_RATIO > MAX_PLATE_RATIO:\n",
        "          continue\n",
        "\n",
        "      plate_imgs.append(img_cropped)\n",
        "      plate_infos.append({\n",
        "          'x': int(plate_cx - plate_width / 2),\n",
        "          'y': int(plate_cy - plate_height / 2),\n",
        "          'w': int(plate_width),\n",
        "          'h': int(plate_height)\n",
        "      })\n",
        "\n",
        "      # plt.subplot(len(filtered_matched_result), 1, i+1)\n",
        "      # plt.imshow(img_cropped, cmap='gray')\n",
        "      # plt.show()\n",
        "\n",
        "  return plate_imgs"
      ],
      "metadata": {
        "id": "Hs6N7entBWpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 번호판 인식"
      ],
      "metadata": {
        "id": "7GLjG3sdZZOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_plate_characters(plate_imgs):\n",
        "  longest_idx, longest_text = -1, 0\n",
        "  plate_chars = []\n",
        "\n",
        "  for i, plate_img in enumerate(plate_imgs):\n",
        "      plate_img = cv2.resize(plate_img, dsize=(0, 0), fx=1.2, fy=1.2)\n",
        "      _, plate_img = cv2.threshold(plate_img, thresh=0.0, maxval=255.0, type=cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "\n",
        "      _, thresh = cv2.threshold(plate_img, 240, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "      # Contour Detection 수행\n",
        "      contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "      # 채워진 원 제거를 위한 마스크 생성\n",
        "      mask = np.ones_like(plate_img) * 255\n",
        "\n",
        "      # Contour를 순회하며 채워진 원을 마스크에 그림\n",
        "      for contour in contours:\n",
        "          area = cv2.contourArea(contour)\n",
        "          perimeter = cv2.arcLength(contour, True)\n",
        "          # Contour를 근사화하여 꼭지점 수 구하기\n",
        "          approx = cv2.approxPolyDP(contour, 0.02 * perimeter, True)\n",
        "          # 채워진 원으로 판별되는 Contour의 내부를 마스크에 채움\n",
        "          if len(approx) > 10:\n",
        "              cv2.drawContours(mask, [contour], -1, 0, thickness=cv2.FILLED)\n",
        "\n",
        "      # 마스크를 사용하여 이미지에서 채워진 원을 제거\n",
        "      plate_img = cv2.bitwise_and(plate_img, plate_img, mask=mask)\n",
        "\n",
        "      plate_min_x, plate_min_y = plate_img.shape[1], plate_img.shape[0]\n",
        "      plate_max_x, plate_max_y = 0, 0\n",
        "\n",
        "      for contour in contours:\n",
        "          x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "          area = w * h\n",
        "          ratio = w / h\n",
        "\n",
        "          if area > MIN_AREA \\\n",
        "          and w > MIN_WIDTH and h > MIN_HEIGHT \\\n",
        "          and MIN_RATIO < ratio < MAX_RATIO:\n",
        "              if x < plate_min_x:\n",
        "                  plate_min_x = x\n",
        "              if y < plate_min_y:\n",
        "                  plate_min_y = y\n",
        "              if x + w > plate_max_x:\n",
        "                  plate_max_x = x + w\n",
        "              if y + h > plate_max_y:\n",
        "                  plate_max_y = y + h\n",
        "\n",
        "      img_result = plate_img[plate_min_y:plate_max_y, plate_min_x:plate_max_x]\n",
        "\n",
        "      # 필요한 후속 처리 진행\n",
        "      img_result = plate_img.copy()\n",
        "      img_result = cv2.GaussianBlur(img_result, ksize=(1, 1), sigmaX=0)\n",
        "      _, img_result = cv2.threshold(img_result, thresh=0.0, maxval=255.0, type=cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "      img_result = cv2.copyMakeBorder(img_result, top=10, bottom=10, left=10, right=10, borderType=cv2.BORDER_CONSTANT, value=(0,0,0))\n",
        "\n",
        "      reader = easyocr.Reader(['ko'], gpu=torch.cuda.is_available())\n",
        "      try:\n",
        "        chars = reader.readtext(img_result, detail=0)[0]\n",
        "      except IndexError:\n",
        "        chars = \"\"\n",
        "\n",
        "      # 결과 필터링: 형식에 맞는 텍스트 추출\n",
        "      result_chars = ''\n",
        "      has_digit = False\n",
        "      # 정규식 패턴: 2-3개의 숫자, 1개의 한글, 4개의 숫자\n",
        "      pattern = re.compile(r'\\d{2,3}[가-힣]\\d{4}')\n",
        "      for c in chars:\n",
        "          if ord('가') <= ord(c) <= ord('힣') or c.isdigit():\n",
        "            if c.isdigit():\n",
        "                  has_digit = True\n",
        "            result_chars += c\n",
        "      # 정규식 패턴으로 필터링\n",
        "      result_chars = pattern.findall(result_chars)\n",
        "      # 결과 출력\n",
        "      plate_chars.append(result_chars)\n",
        "\n",
        "      if has_digit and len(result_chars) > longest_text:\n",
        "          longest_idx = i\n",
        "\n",
        "      # plt.subplot(len(plate_imgs), 1, i+1)\n",
        "      # plt.imshow(img_result, cmap='gray')\n",
        "      # plt.show()\n",
        "\n",
        "      # print(result_chars)\n",
        "\n",
        "      return result_chars"
      ],
      "metadata": {
        "id": "Xu7gl6JmHcMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 전체 과정"
      ],
      "metadata": {
        "id": "ehz55u46ZjEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 이미지 폴더 적용"
      ],
      "metadata": {
        "id": "Yo2FHMcenqMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plate 폴더 경로\n",
        "plate_folder = '/content/drive/MyDrive/AID/plate'\n",
        "\n",
        "# plate 폴더 내의 하위 폴더들을 리스트로 저장\n",
        "subfolders = [os.path.join(plate_folder, subfolder) for subfolder in os.listdir(plate_folder)]\n",
        "subfolders = sorted(subfolders)\n",
        "\n",
        "plate_list = ['103우2951', '36더0252', '55소6637']\n",
        "plate_list = [[plate] for plate in plate_list]\n",
        "sum1 = [0] * 3\n",
        "sum2 = [0] * 3\n",
        "cnt = [0] * 3\n",
        "\n",
        "# 각 하위 폴더를 순회하며 이미지 파일 처리\n",
        "for i, subfolder in enumerate(subfolders):\n",
        "    image_files = os.listdir(subfolder)\n",
        "    sum1[i] = len(image_files)\n",
        "    cnt[i] = 0\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(subfolder, image_file)\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        outs, height, width = process_image(image)\n",
        "        boxes, confidences, class_ids, indexes = detect_object(outs, width, height)\n",
        "        detected_car_images, car_confidences = detect_car(boxes, confidences, class_ids, indexes)\n",
        "        best_car_img = select_car(detected_car_images, car_confidences)\n",
        "\n",
        "        height, width, channel = show_image(best_car_img)\n",
        "\n",
        "        gray = convert_to_gray(best_car_img)\n",
        "\n",
        "        img_blurred = blur_image(gray)\n",
        "\n",
        "        img_thresh = threshold_image(img_blurred)\n",
        "\n",
        "        contours, temp_result = find_contours(img_thresh, height, width, channel)\n",
        "\n",
        "        contours_dict = visualize_contours(contours, temp_result)\n",
        "\n",
        "        possible_contours = draw_bounding_boxes(contours_dict, height, width, channel)\n",
        "\n",
        "        matched_result = find_matching_contours(possible_contours, height, width, channel)\n",
        "\n",
        "        plate_imgs = extract_plate_images(matched_result, img_thresh, width, height)\n",
        "\n",
        "        result_chars = extract_plate_characters(plate_imgs)\n",
        "\n",
        "        if result_chars == plate_list[i]:\n",
        "          cnt[i] += 1\n",
        "        if result_chars != []:\n",
        "          sum2[i] += 1"
      ],
      "metadata": {
        "id": "1GjZ8iPXbivp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db89cf20-0928-4e7a-be0e-943eb75daacd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.1% Complete"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 정확도"
      ],
      "metadata": {
        "id": "TkZtgsRbasLi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### empty 포함"
      ],
      "metadata": {
        "id": "pDTm4Fy9hwTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(plate_list)):\n",
        "  print(plate_list[i])\n",
        "  print(f'{cnt[i]}/{sum1[i]} = {cnt[i] / sum1[i]}')\n",
        "print(f'-> {sum(cnt)}/{sum(sum1)} = {sum(cnt) / sum(sum1)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGzDBLrFXl_u",
        "outputId": "1eaf31e0-e73c-42bc-cd0f-3d82028bec06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['103우2951']\n",
            "8/10 = 0.8\n",
            "['36더0252']\n",
            "22/34 = 0.6470588235294118\n",
            "['55소6637']\n",
            "22/31 = 0.7096774193548387\n",
            "-> 52/75 = 0.6933333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### empty 미포함"
      ],
      "metadata": {
        "id": "yF87ULJChycn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(plate_list)):\n",
        "  print(plate_list[i])\n",
        "  print(f'{cnt[i]}/{sum2[i]} = {cnt[i] / sum2[i]}')\n",
        "print(f'-> {sum(cnt)}/{sum(sum2)} = {sum(cnt) / sum(sum2)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go5NoJdjXnIT",
        "outputId": "c1e403ea-516d-4662-ba16-e7307b2b6be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['103우2951']\n",
            "8/9 = 0.8888888888888888\n",
            "['36더0252']\n",
            "22/24 = 0.9166666666666666\n",
            "['55소6637']\n",
            "22/23 = 0.9565217391304348\n",
            "-> 52/56 = 0.9285714285714286\n"
          ]
        }
      ]
    }
  ]
}